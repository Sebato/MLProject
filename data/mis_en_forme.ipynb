{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f3764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/e20220002252/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/e20220002252/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /home/e20220002252/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/e20220002252/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/e20220002252/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2023-03-13 11:32:18.520848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 11:32:19.686859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-13 11:32:19.687119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-13 11:32:19.687125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-13 11:32:21.026224: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-13 11:32:21.026243: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fds0916): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92739/3286142814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# !python -m spacy download en_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# Importation des différentes librairies utiles pour le notebook\n",
    "\n",
    "#Sickit learn met régulièrement à jour des versions et \n",
    "#indique des futurs warnings. \n",
    "#ces deux lignes permettent de ne pas les afficher.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# librairies générales\n",
    "import pickle \n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import base64\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import contractions\n",
    "\n",
    "# librairie BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# librairie affichage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "\n",
    "## detection de language\n",
    "import langdetect \n",
    "\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk import RegexpParser\n",
    "# il est possible de charger l'ensemble des librairies en une seule fois \n",
    "# décocher le commentaire de la ligne ci-dessous\n",
    "#nltk.download('all') \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "nltk.download('tagsets')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "# il faut sélectionner pour quelle langue les traitements vont être faits.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65efafa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/e20220002252/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/e20220002252/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee39e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>public_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>our rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a228e0e</td>\n",
       "      <td>Distracted driving causes more deaths in Canad...</td>\n",
       "      <td>You Can Be Fined $1,500 If Your Passenger Is U...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c605a1</td>\n",
       "      <td>Missouri politicians have made statements afte...</td>\n",
       "      <td>Missouri lawmakers condemn Las Vegas shooting</td>\n",
       "      <td>mixture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c3dea290</td>\n",
       "      <td>Home Alone 2: Lost in New York is full of viol...</td>\n",
       "      <td>CBC Cuts Donald Trump's 'Home Alone 2' Cameo O...</td>\n",
       "      <td>mixture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f14e8eb6</td>\n",
       "      <td>But things took a turn for the worse when riot...</td>\n",
       "      <td>Obama’s Daughters Caught on Camera Burning US ...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faf024d6</td>\n",
       "      <td>It’s no secret that Epstein and Schiff share a...</td>\n",
       "      <td>Leaked Visitor Logs Reveal Schiff’s 78 Visits ...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  public_id                                               text  \\\n",
       "0  5a228e0e  Distracted driving causes more deaths in Canad...   \n",
       "1  30c605a1  Missouri politicians have made statements afte...   \n",
       "2  c3dea290  Home Alone 2: Lost in New York is full of viol...   \n",
       "3  f14e8eb6  But things took a turn for the worse when riot...   \n",
       "4  faf024d6  It’s no secret that Epstein and Schiff share a...   \n",
       "\n",
       "                                               title our rating  \n",
       "0  You Can Be Fined $1,500 If Your Passenger Is U...      false  \n",
       "1      Missouri lawmakers condemn Las Vegas shooting    mixture  \n",
       "2  CBC Cuts Donald Trump's 'Home Alone 2' Cameo O...    mixture  \n",
       "3  Obama’s Daughters Caught on Camera Burning US ...      false  \n",
       "4  Leaked Visitor Logs Reveal Schiff’s 78 Visits ...      false  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/HAI817_Projet_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068e3ef",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "### Création de liste des mots qui apparaissent dans le texte et dans le titre de chaque document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6bd6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(dataframe):    \n",
    "    full_texts = []\n",
    "    for i in range(len(dataframe)):\n",
    "        full_texts.append((str(dataframe.iloc[i].title) + \" \" + str(dataframe.iloc[i].text)))\n",
    "    tokens = [t.split() for t in full_texts]\n",
    "    tokens = [[t.lower() for t in lt] for lt in tokens]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76d05256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_stopwords(words, stopwords):\n",
    "    return [word for word in words if word not in stopwords]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "722bc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(dataframe):\n",
    "    \"\"\" \"\"\"\n",
    "    ps=nltk.stem.porter.PorterStemmer()\n",
    "    dataframe[\"tokens\"].transform(lambda tokens: [ps.stem(word) for word in tokens])\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd6947d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataframe, classes):\n",
    "    dataframe[\"tokens\"] = get_tokens(dataframe)\n",
    "    \n",
    "    swords = set(stopwords.words(\"english\"))\n",
    "    dataframe[\"tokens\"] = dataframe[\"tokens\"].transform(lambda t: [word for word in t if word not in swords])\n",
    "    \n",
    "    ps=nltk.stem.porter.PorterStemmer()\n",
    "    dataframe[\"tokens\"] = dataframe[\"tokens\"].transform(lambda tokens: [ps.stem(word) for word in tokens])\n",
    "\n",
    "    dataframe = dataframe[dataframe[\"our rating\"].isin(classes)]\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1e7726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = prepare_data(df, [\"true\", \"false\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6fe0a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>public_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>our rating</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a228e0e</td>\n",
       "      <td>Distracted driving causes more deaths in Canad...</td>\n",
       "      <td>You Can Be Fined $1,500 If Your Passenger Is U...</td>\n",
       "      <td>false</td>\n",
       "      <td>[fine, $1,500, passeng, use, mobil, phone,, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f14e8eb6</td>\n",
       "      <td>But things took a turn for the worse when riot...</td>\n",
       "      <td>Obama’s Daughters Caught on Camera Burning US ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[obama’, daughter, caught, camera, burn, us, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faf024d6</td>\n",
       "      <td>It’s no secret that Epstein and Schiff share a...</td>\n",
       "      <td>Leaked Visitor Logs Reveal Schiff’s 78 Visits ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[leak, visitor, log, reveal, schiff’, 78, visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61bd9a69</td>\n",
       "      <td>November 23, 2019  The U.S. Food and Drug Admi...</td>\n",
       "      <td>FDA Shocking Study: Cells Used In Vaccines Con...</td>\n",
       "      <td>false</td>\n",
       "      <td>[fda, shock, study:, cell, use, vaccin, contam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb1999cc</td>\n",
       "      <td>Trump confirms this was a bombing, not an acci...</td>\n",
       "      <td>Israel Hits Beirut with Nuclear Missile, Trump...</td>\n",
       "      <td>false</td>\n",
       "      <td>[israel, hit, beirut, nuclear, missile,, trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c1dc1ac6</td>\n",
       "      <td>In a show of anti-American sentiment that will...</td>\n",
       "      <td>Obama’s Daughters Caught on Camera Burning US ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[obama’, daughter, caught, camera, burn, us, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2182a54</td>\n",
       "      <td>FEMA camps, portable human cages, it's all rea...</td>\n",
       "      <td>Fields of human cages discovered in Caruthers ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[field, human, cage, discov, caruth, californi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2ec747ae</td>\n",
       "      <td>Submitted by Great Game India  Last year a mys...</td>\n",
       "      <td>Did China Steal Coronavirus From Canada And We...</td>\n",
       "      <td>false</td>\n",
       "      <td>[china, steal, coronaviru, canada, weapon, it?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c69de08e</td>\n",
       "      <td>The proportion of people living in poverty who...</td>\n",
       "      <td>Number of people in poverty in working familie...</td>\n",
       "      <td>false</td>\n",
       "      <td>[number, peopl, poverti, work, famili, hit, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>392886ea</td>\n",
       "      <td>“I love what he says, I have to admit.” That w...</td>\n",
       "      <td>Kenny Rogers’ Wife Donates Half His Estate To ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[kenni, rogers’, wife, donat, half, estat, tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d72c2323</td>\n",
       "      <td>LA CROSSE, WIS — Kwik Trip, Inc. has officiall...</td>\n",
       "      <td>Kwik Trip Launches Kwik Strip Gentlemen’s Clubs</td>\n",
       "      <td>false</td>\n",
       "      <td>[kwik, trip, launch, kwik, strip, gentlemen’, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1a7b60cc</td>\n",
       "      <td>Michigan now admits after ‘certifying’ the 202...</td>\n",
       "      <td>Michigan Removed 177,000 Voters from Voter Rol...</td>\n",
       "      <td>false</td>\n",
       "      <td>[michigan, remov, 177,000, voter, voter, roll,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>59960d0e</td>\n",
       "      <td>Police in Los Angeles have thwarted and appare...</td>\n",
       "      <td>Police Stop Man From Dumping LSD Into L.A. Wat...</td>\n",
       "      <td>false</td>\n",
       "      <td>[polic, stop, man, dump, lsd, l.a., water, sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4461868e</td>\n",
       "      <td>If you still think mail-in ballots are a safe ...</td>\n",
       "      <td>Dem Senator Knope Caught With 8000 Mail-In Bal...</td>\n",
       "      <td>false</td>\n",
       "      <td>[dem, senat, knope, caught, 8000, mail-in, bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>213a870b</td>\n",
       "      <td>Have an important tip? Let us know. Email us h...</td>\n",
       "      <td>Smoking Gun! Joe Biden’s Dept. of Energy Block...</td>\n",
       "      <td>false</td>\n",
       "      <td>[smoke, gun!, joe, biden’, dept., energi, bloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>e2e93a55</td>\n",
       "      <td>An undercover investigation into the actual de...</td>\n",
       "      <td>Shell Corporation That Legally Owns Epstein’s ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[shell, corpor, legal, own, epstein’, island, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1f33d253</td>\n",
       "      <td>Pro-choice protesters chant slogans at a prote...</td>\n",
       "      <td>Northern Ireland legally allows abortions for ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[northern, ireland, legal, allow, abort, rape,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7c9af097</td>\n",
       "      <td>In Brief The Facts: It is alleged by many in t...</td>\n",
       "      <td>Scientist Explains Why He Believes Aluminum Is...</td>\n",
       "      <td>false</td>\n",
       "      <td>[scientist, explain, believ, aluminum, “almost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5929f661</td>\n",
       "      <td>Democrat candidate Joe Biden has ended “in-per...</td>\n",
       "      <td>Biden Calls a “lid” on His Campaign, He is Don...</td>\n",
       "      <td>false</td>\n",
       "      <td>[biden, call, “lid”, campaign,, done, meet, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c33779f6</td>\n",
       "      <td>WHO: You Do NOT Need to Wear a Mask  January 2...</td>\n",
       "      <td>WHO now saying You do not need to Wear a Mask</td>\n",
       "      <td>false</td>\n",
       "      <td>[say, need, wear, mask, who:, need, wear, mask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>409c20fd</td>\n",
       "      <td>Just days after courting controversy by forbid...</td>\n",
       "      <td>NASCAR Prohibits MAGA Hats, ‘Political’ Clothing</td>\n",
       "      <td>false</td>\n",
       "      <td>[nascar, prohibit, maga, hats,, ‘political’, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1703c7b3</td>\n",
       "      <td>Today, Congressman Glenn Grothman WI-06 releas...</td>\n",
       "      <td>Grothman on Blacklisting of Mother, Father, So...</td>\n",
       "      <td>false</td>\n",
       "      <td>[grothman, blacklist, mother,, father,, son,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>da55bc13</td>\n",
       "      <td>It is absolutely right that across this House ...</td>\n",
       "      <td>Wednesday 25 April 2018</td>\n",
       "      <td>true</td>\n",
       "      <td>[wednesday, 25, april, 2018, absolut, right, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58b61315</td>\n",
       "      <td>Dr. Anthony Fauci, whose “expert” advice to Pr...</td>\n",
       "      <td>Fauci knew about HCQ in 2005 -- nobody needed ...</td>\n",
       "      <td>false</td>\n",
       "      <td>[fauci, knew, hcq, 2005, --, nobodi, need, die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b5bf9ed6</td>\n",
       "      <td>Update 1040ET: Science moves fast during an ou...</td>\n",
       "      <td>Coronavirus Contains HIV Insertions, Stoking F...</td>\n",
       "      <td>false</td>\n",
       "      <td>[coronaviru, contain, hiv, insertions,, stoke,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   public_id                                               text  \\\n",
       "0   5a228e0e  Distracted driving causes more deaths in Canad...   \n",
       "1   f14e8eb6  But things took a turn for the worse when riot...   \n",
       "2   faf024d6  It’s no secret that Epstein and Schiff share a...   \n",
       "3   61bd9a69  November 23, 2019  The U.S. Food and Drug Admi...   \n",
       "4   bb1999cc  Trump confirms this was a bombing, not an acci...   \n",
       "5   c1dc1ac6  In a show of anti-American sentiment that will...   \n",
       "6   f2182a54  FEMA camps, portable human cages, it's all rea...   \n",
       "7   2ec747ae  Submitted by Great Game India  Last year a mys...   \n",
       "8   c69de08e  The proportion of people living in poverty who...   \n",
       "9   392886ea  “I love what he says, I have to admit.” That w...   \n",
       "10  d72c2323  LA CROSSE, WIS — Kwik Trip, Inc. has officiall...   \n",
       "11  1a7b60cc  Michigan now admits after ‘certifying’ the 202...   \n",
       "12  59960d0e  Police in Los Angeles have thwarted and appare...   \n",
       "13  4461868e  If you still think mail-in ballots are a safe ...   \n",
       "14  213a870b  Have an important tip? Let us know. Email us h...   \n",
       "15  e2e93a55  An undercover investigation into the actual de...   \n",
       "16  1f33d253  Pro-choice protesters chant slogans at a prote...   \n",
       "17  7c9af097  In Brief The Facts: It is alleged by many in t...   \n",
       "18  5929f661  Democrat candidate Joe Biden has ended “in-per...   \n",
       "19  c33779f6  WHO: You Do NOT Need to Wear a Mask  January 2...   \n",
       "20  409c20fd  Just days after courting controversy by forbid...   \n",
       "21  1703c7b3  Today, Congressman Glenn Grothman WI-06 releas...   \n",
       "22  da55bc13  It is absolutely right that across this House ...   \n",
       "23  58b61315  Dr. Anthony Fauci, whose “expert” advice to Pr...   \n",
       "24  b5bf9ed6  Update 1040ET: Science moves fast during an ou...   \n",
       "\n",
       "                                                title our rating  \\\n",
       "0   You Can Be Fined $1,500 If Your Passenger Is U...      false   \n",
       "1   Obama’s Daughters Caught on Camera Burning US ...      false   \n",
       "2   Leaked Visitor Logs Reveal Schiff’s 78 Visits ...      false   \n",
       "3   FDA Shocking Study: Cells Used In Vaccines Con...      false   \n",
       "4   Israel Hits Beirut with Nuclear Missile, Trump...      false   \n",
       "5   Obama’s Daughters Caught on Camera Burning US ...      false   \n",
       "6   Fields of human cages discovered in Caruthers ...      false   \n",
       "7   Did China Steal Coronavirus From Canada And We...      false   \n",
       "8   Number of people in poverty in working familie...      false   \n",
       "9   Kenny Rogers’ Wife Donates Half His Estate To ...      false   \n",
       "10    Kwik Trip Launches Kwik Strip Gentlemen’s Clubs      false   \n",
       "11  Michigan Removed 177,000 Voters from Voter Rol...      false   \n",
       "12  Police Stop Man From Dumping LSD Into L.A. Wat...      false   \n",
       "13  Dem Senator Knope Caught With 8000 Mail-In Bal...      false   \n",
       "14  Smoking Gun! Joe Biden’s Dept. of Energy Block...      false   \n",
       "15  Shell Corporation That Legally Owns Epstein’s ...      false   \n",
       "16  Northern Ireland legally allows abortions for ...      false   \n",
       "17  Scientist Explains Why He Believes Aluminum Is...      false   \n",
       "18  Biden Calls a “lid” on His Campaign, He is Don...      false   \n",
       "19      WHO now saying You do not need to Wear a Mask      false   \n",
       "20   NASCAR Prohibits MAGA Hats, ‘Political’ Clothing      false   \n",
       "21  Grothman on Blacklisting of Mother, Father, So...      false   \n",
       "22                            Wednesday 25 April 2018       true   \n",
       "23  Fauci knew about HCQ in 2005 -- nobody needed ...      false   \n",
       "24  Coronavirus Contains HIV Insertions, Stoking F...      false   \n",
       "\n",
       "                                               tokens  \n",
       "0   [fine, $1,500, passeng, use, mobil, phone,, st...  \n",
       "1   [obama’, daughter, caught, camera, burn, us, f...  \n",
       "2   [leak, visitor, log, reveal, schiff’, 78, visi...  \n",
       "3   [fda, shock, study:, cell, use, vaccin, contam...  \n",
       "4   [israel, hit, beirut, nuclear, missile,, trump...  \n",
       "5   [obama’, daughter, caught, camera, burn, us, f...  \n",
       "6   [field, human, cage, discov, caruth, californi...  \n",
       "7   [china, steal, coronaviru, canada, weapon, it?...  \n",
       "8   [number, peopl, poverti, work, famili, hit, re...  \n",
       "9   [kenni, rogers’, wife, donat, half, estat, tru...  \n",
       "10  [kwik, trip, launch, kwik, strip, gentlemen’, ...  \n",
       "11  [michigan, remov, 177,000, voter, voter, roll,...  \n",
       "12  [polic, stop, man, dump, lsd, l.a., water, sup...  \n",
       "13  [dem, senat, knope, caught, 8000, mail-in, bal...  \n",
       "14  [smoke, gun!, joe, biden’, dept., energi, bloc...  \n",
       "15  [shell, corpor, legal, own, epstein’, island, ...  \n",
       "16  [northern, ireland, legal, allow, abort, rape,...  \n",
       "17  [scientist, explain, believ, aluminum, “almost...  \n",
       "18  [biden, call, “lid”, campaign,, done, meet, in...  \n",
       "19  [say, need, wear, mask, who:, need, wear, mask...  \n",
       "20  [nascar, prohibit, maga, hats,, ‘political’, c...  \n",
       "21  [grothman, blacklist, mother,, father,, son,, ...  \n",
       "22  [wednesday, 25, april, 2018, absolut, right, a...  \n",
       "23  [fauci, knew, hcq, 2005, --, nobodi, need, die...  \n",
       "24  [coronaviru, contain, hiv, insertions,, stoke,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(display(df_train.head(25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a374a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_bag(dataframe):\n",
    "    corpus = dataframe[\"tokens\"].transform(lambda s: \" \".join(s)).tolist()\n",
    "    vectorizer = CountVectorizer()\n",
    "    # creation du vocabulaire\n",
    "    vector = vectorizer.fit_transform(corpus)\n",
    "    df = pd.DataFrame(data=vectorizer.transform(corpus).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    df.insert(0, \"our_rating\", dataframe[\"our rating\"])\n",
    "    return (vectorizer, df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f0cd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag, bag_train = create_bag(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48087bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>our_rating</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0008</th>\n",
       "      <th>000m</th>\n",
       "      <th>000x</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>003</th>\n",
       "      <th>005</th>\n",
       "      <th>...</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerburg</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwar</th>\n",
       "      <th>zxc21</th>\n",
       "      <th>zzt2briay</th>\n",
       "      <th>ärzteblatt</th>\n",
       "      <th>único</th>\n",
       "      <th>μm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  our_rating  00  000  0008  000m  000x  001  002  003  005  ...  zucker  \\\n",
       "0      false   0    0     0     0     0    0    0    0    0  ...       0   \n",
       "1      false   0    0     0     0     0    0    0    0    0  ...       0   \n",
       "2      false   0    0     0     0     0    0    0    0    0  ...       0   \n",
       "3      false   0    0     0     0     0    0    0    0    0  ...       0   \n",
       "4      false   0    0     0     0     0    0    0    0    0  ...       0   \n",
       "\n",
       "   zuckerburg  zundel  zurich  zwar  zxc21  zzt2briay  ärzteblatt  único  μm  \n",
       "0           0       0       0     0      0          0           0      0   0  \n",
       "1           0       0       0     0      0          0           0      0   0  \n",
       "2           0       0       0     0      0          0           0      0   0  \n",
       "3           0       0       0     0      0          0           0      0   0  \n",
       "4           0       0       0     0      0          0           0      0   0  \n",
       "\n",
       "[5 rows x 23271 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3cf7a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13f365d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.831435 (0.040826)\n",
      "KNN: 0.762999 (0.051546)\n",
      "NB: 0.783268 (0.048845)\n",
      "SVC: 0.749075 (0.059213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92739/3143848669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = bag_train.values[:, 1:]\n",
    "y = bag_train.values[:, 0]\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC(gamma='auto')))\n",
    "models.append(('LSVC', LinearSVC()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "\n",
    "seed = 7\n",
    "results = []\n",
    "names = []\n",
    "scoring='accuracy'\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed,shuffle=True)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ab6ff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20220002252/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987325728770595\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "res = clf.score(X, y)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef88e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
